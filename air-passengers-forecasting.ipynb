{"cells":[{"metadata":{},"cell_type":"markdown","source":"TS is a collection of data points collected at constant time intervals. These are analyzed to determine the long term trend so as to forecast the future or perform some other form of analysis.<br>We’ll be using the popular AirPassengers data set."},{"metadata":{},"cell_type":"markdown","source":"# Import necessary libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport statsmodels.api as sm\nimport warnings","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import the AirPassengers dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers = pd.read_csv('../input/air-passengers/AirPassengers.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting the 'Month' column into proper date time format"},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = pd.date_range(start='1949-01-01', freq='MS',periods=len(passengers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers['Month'] = dates.month\npassengers['Year'] = dates.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To get the names of the month"},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import calendar\npassengers['Month'] = passengers['Month'].apply(lambda x: calendar.month_abbr[x])\npassengers.rename({'#Passengers':'Passengers'},axis=1,inplace=True)\npassengers = passengers[['Month','Year','Passengers']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers['Date'] = dates\npassengers.set_index('Date',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\npassengers.groupby('Year')['Passengers'].mean().plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('From the above figure we can see that passengers are increasing with the increase in the year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\npassengers.groupby('Month')['Passengers'].mean().reindex(index=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']).plot(kind='bar')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('From the above figure we can see that more passengers can be seen between months June to September.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets plot the data to see the trend and seasonality"},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers_count = passengers['Passengers']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\npassengers_count.plot()\nplt.xlabel('Year')\nplt.ylabel('Number of Passengers')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now we start with time series decomposition of this data to understand underlying patterns such as trend, seasonality, cycle and irregular remainder\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"decompose = sm.tsa.seasonal_decompose(passengers_count,model='multiplicative',extrapolate_trend=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = decompose.plot()\nfig.set_figheight(10)\nfig.set_figwidth(8)\nfig.suptitle('Decomposition of Time Series')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b> Trend</b><br>\nTime Series Decomposition: To begin with let's try to decipher trends embedded in the above tractor sales time series. It is clearly evident that there is an overall increasing trend in the data along with some seasonal variations. However, it might not always be possible to make such visual inferences.<br> So, more formally, we can check stationarity using the following: Plotting Rolling Statistics: We can plot the moving average or moving variance and see if it varies with time. By moving average/variance we mean that at any instant 't', we'll take the average/variance of the last year, i.e. last 12 months. But again this is more of a visual technique.<br>\nNow, let’s try to remove wrinkles from our time series using moving average. We will take moving average of different time periods i.e. 4,6,8, and 12 months as shown below. Here, moving average is shown in <b>orange</b> and actual series in <b>blue</b>."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(2,2)\nfig.set_figheight(10)\nfig.set_figwidth(15)\naxes[0][0].plot(passengers.index,passengers_count,label='Actual')\naxes[0][0].plot(passengers.index,passengers_count.rolling(window=4).mean(),label='4 months rolling mean')\naxes[0][0].set_xlabel('Year')\naxes[0][0].set_ylabel('Number of Passengers')\naxes[0][0].set_title('4 Months Rolling Mean')\naxes[0][0].legend(loc='best')\n\n\naxes[0][1].plot(passengers.index,passengers_count,label='Actual')\naxes[0][1].plot(passengers.index,passengers_count.rolling(window=6).mean(),label='6 months rolling mean')\naxes[0][1].set_xlabel('Year')\naxes[0][1].set_ylabel('Number of Passengers')\naxes[0][1].set_title('6 Months Rolling Mean')\naxes[0][1].legend(loc='best')\n\n\n\naxes[1][0].plot(passengers.index,passengers_count,label='Actual')\naxes[1][0].plot(passengers.index,passengers_count.rolling(window=8).mean(),label='8 months rolling mean')\naxes[1][0].set_xlabel('Year')\naxes[1][0].set_ylabel('Number of Passengers')\naxes[1][0].set_title('8 Months Rolling Mean')\naxes[1][0].legend(loc='best')\n\n\naxes[1][1].plot(passengers.index,passengers_count,label='Actual')\naxes[1][1].plot(passengers.index,passengers_count.rolling(window=12).mean(),label='12 months rolling mean')\naxes[1][1].set_xlabel('Year')\naxes[1][1].set_ylabel('Number of Passengers')\naxes[1][1].set_title('12 Months Rolling Mean')\naxes[1][1].legend(loc='best')\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we could see in the above plots, 12-month moving average could produce a wrinkle free curve as desired. This on some level is expected since we are using month-wise data for our analysis and there is expected monthly-seasonal effect in our data."},{"metadata":{},"cell_type":"markdown","source":"<b>Seasonality</b><br>\nLet us see how many passengers travelled in flights on a month on month basis. We will plot a stacked annual plot to observe seasonality in our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly = pd.pivot_table(data=passengers,values='Passengers',index='Month',columns='Year')\nmonthly = monthly.reindex(index=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly.plot(figsize=(8,6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"yearly = pd.pivot_table(data=passengers,values='Passengers',index='Year',columns='Month')\nyearly = yearly[['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yearly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yearly.plot(figsize=(8,6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yearly.plot(kind='box',figsize=(8,6))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Important Inferences\n\nThe passengers are increasing without fail every year.<br><br>\nJuly and August are the peak months for passengers.<br>\n\nWe can see a seasonal cycle of 12 months where the mean value of each month starts with a increasing trend in the beginning of the year and drops down towards the end of the year. We can see a seasonal effect with a cycle of 12 months.\n"},{"metadata":{},"cell_type":"markdown","source":"# ARIMA Modelling"},{"metadata":{},"cell_type":"markdown","source":"### Dickey-Fuller Test \nThe most important assumption of auto regressive method is that the TS data should be stationary.<br>\n\nLet's run the Dicky Fuller Test on the timeseries and verify the null hypothesis that the TS is non-stationary."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform Dickey-Fuller test:\nfrom statsmodels.tsa.stattools import adfuller\nadfuller(passengers_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adfuller_results = pd.Series(adfuller(passengers_count)[:4],index=['T stats','p-value','lags used','Number of observations'])\nfor key,value in adfuller(passengers_count)[4].items():\n    adfuller_results['Critical Value'+' '+ key] = value\nprint(adfuller_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The p-value is greater than 0.05 (Coinfidence Interval 95%).<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers_count.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do log transformation to convert the TS to stationary TS"},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers_log = np.log10(passengers_count)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"passengers_log.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform Dickey-Fuller test:\nfrom statsmodels.tsa.stattools import adfuller\nadfuller(passengers_log)\nadfuller_results = pd.Series(adfuller(passengers_log)[:4],index=['T stats','p-value','lags used','Number of observations'])\nfor key,value in adfuller(passengers_log)[4].items():\n    adfuller_results['Critical Value (%s)'%key] = value\nprint(adfuller_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The p-value is still greater than 0.05 (Coinfidence Interval 95%).<br>\nThe log transformation has made variance stationary but mean is still increasing.<br>\nLet's try differencing by 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"diff1 = passengers_count.diff(1)\ndiff1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff1.dropna(axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diff1.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform Dickey-Fuller test:\nfrom statsmodels.tsa.stattools import adfuller\nadfuller(diff1)\nadfuller_results = pd.Series(adfuller(diff1)[:4],index=['T stats','p-value','lags used','Number of observations'])\nfor key,value in adfuller(diff1)[4].items():\n    adfuller_results['Critical Value (%s)'%key] = value\nprint(adfuller_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The p-value is still greater than 0.05 (Coinfidence Interval 95%).<br>\nThe differencing by 1 has made mean stationary but variance is changing.<br>\nLet's try differencing by 1 on the log transformation."},{"metadata":{"trusted":true},"cell_type":"code","source":"log_diff1 = passengers_log.diff(1)\nlog_diff1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_diff1.dropna(axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_diff1.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform Dickey-Fuller test:\nfrom statsmodels.tsa.stattools import adfuller\nadfuller(log_diff1)\nadfuller_results = pd.Series(adfuller(log_diff1)[:4],index=['T stats','p-value','lags used','Number of observations'])\nfor key,value in adfuller(log_diff1)[4].items():\n    adfuller_results['Critical Value (%s)'%key] = value\nprint(adfuller_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"p-value is still greateer than 0.05. "},{"metadata":{"trusted":true},"cell_type":"code","source":"log_diff2 = passengers_log.diff(2)\nlog_diff2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_diff2.dropna(axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_diff2.plot()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perform Dickey-Fuller test:\nfrom statsmodels.tsa.stattools import adfuller\nadfuller(log_diff2)\nadfuller_results = pd.Series(adfuller(log_diff2)[:4],index=['T stats','p-value','lags used','Number of observations'])\nfor key,value in adfuller(log_diff2)[4].items():\n    adfuller_results['Critical Value (%s)'%key] = value\nprint(adfuller_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"p-value is less than 0.05. In this case we reject null hypothesis that TS is non stationary."},{"metadata":{},"cell_type":"markdown","source":"# ARIMA Modeling\nARIMA is a combination of 3 parts i.e. AR (AutoRegressive), I (Integrated), and MA (Moving Average). A convenient notation for ARIMA model is ARIMA(p,d,q). Here p,d, and q are the levels for each of the AR, I, and MA parts. Each of these three parts is an effort to make the final residuals display a white noise pattern (or no pattern at all). In each step of ARIMA modeling, time series data is passed through these 3 parts like a sugar cane through a sugar cane juicer to produce juice-less residual. The sequence of three passes for ARIMA analysis is as following:\n\n1st Pass of ARIMA to Extract Juice / Information\nIntegrated (I) – subtract time series with its lagged series to extract trends from the data\nIn this pass of ARIMA juicer, we extract trend(s) from the original time series data. Differencing is one of the most commonly used mechanisms for extraction of trends. Here, the original series is subtracted with it’s lagged series e.g. November’s sales values are subtracted with October’s values to produce trend-less residual series. The formulae for different orders of differencing are as follow:\n\n- No Differencing (d=0) |  Y′t=YtYt′=Yt \n- 1st Differencing (d=1) |  Y′t=Yt−Yt−1Yt′=Yt−Yt−1 \n- 2nd Differencing (d=1) |  Y′t=Yt−Yt−1−(Yt−1−Yt−2)=Yt−2×Yt−1+Yt−2Yt′=Yt−Yt−1−(Yt−1−Yt−2)=Yt−2×Yt−1+Yt−2 "},{"metadata":{},"cell_type":"markdown","source":"## Identification of best fit ARIMA model\n\nIn order to fit the time series data with a seasonal ARIMA model, we need to first find the the values of ARIMA(p,d,q)(P,D,Q)s that optimize a metric of interest such as AIC or BIC. There are many guidelines and best practices to achieve this goal, yet the correct parametrization of ARIMA models can be a painstaking manual process that requires domain expertise and time. Auto arima function in forecast package in R helps us identify the best fit ARIMA model on the fly but in Python we will generate combination of p,d and q to select the optimal parameter values for our ARIMA(p,d,q)(P,D,Q)s time series model.\nThis technique is known as \"grid search\" where we iteratively explore different combinations of parameters. For each such combination of parameters, we try to fit a new seasonal ARIMA model with the SARIMAX() function from the statsmodels module and assess AIC or BIC score. The model with the best score wins and the parmeters for that model are the optimal parmeters."},{"metadata":{},"cell_type":"markdown","source":"### Iterate the process to find the best values for p, d, q and P, D, Q"},{"metadata":{"trusted":true},"cell_type":"code","source":"import itertools\n# Define the p, d and q parameters to take any value between 0 and 2\np = q = range(0, 3)\nd = range(0,1)\n# Generate all different combinations of p, d and q triplets\npdq = list(itertools.product(p, d, q))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pdq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate all different combinations of seasonal p, q and q triplets\nD = range(0,3)\nP = Q = range(0, 3) \nseasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(P, D, Q))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seasonal_pdq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nwarnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n\nbest_aic = np.inf\nbest_pdq = None\nbest_seasonal_pdq = None\ntemp_model = None\n\nfor param in pdq:\n    for param_seasonal in seasonal_pdq:\n       \n        try:\n            temp_model = sm.tsa.statespace.SARIMAX(log_diff2,\n                                             order = param,\n                                             seasonal_order = param_seasonal,\n                                             enforce_stationarity=False,\n                                             enforce_invertibility=False)\n            results = temp_model.fit()\n\n           # print(\"SARIMAX{}x{}12 - AIC:{}\".format(param, param_seasonal, results.aic))\n            if results.aic < best_aic:\n                best_aic = results.aic\n                best_pdq = param\n                best_seasonal_pdq = param_seasonal\n        except:\n            #print(\"Unexpected error:\", sys.exc_info()[0])\n            continue\nprint(\"Best SARIMAX{}x{}12 model - AIC:{}\".format(best_pdq, best_seasonal_pdq, best_aic))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best SARIMAX(1, 0, 1)x(1, 0, 1, 12)12 model - AIC:-671.0386830029513\nThe best fit model is selected based on Akaike Information Criterion (AIC) , and Bayesian Information Criterion (BIC) values. The idea is to choose a model with minimum AIC and BIC values."},{"metadata":{},"cell_type":"markdown","source":"### Predict sales on in-sample date using the best fit ARIMA model\nThe next step is to predict passengers\nfor in-sample data and find out how close is the model prediction on the in-sample data to the actual truth."},{"metadata":{"trusted":true},"cell_type":"code","source":"sarima = sm.tsa.statespace.SARIMAX(log_diff2,order=(1,0,1),seasonal_order=(1,0,1,12),enforce_invertibility=False,enforce_stationarity=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sarima_results = sarima.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sarima_results.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"passengers_count.tail(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = sarima_results.get_prediction(start=pd.to_datetime('1960-01-01'),full_results=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction.predicted_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_values = np.power(10,prediction.predicted_mean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"actual = passengers_count['1960-01-01':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean absolute percentage error\nmape = np.mean(np.abs(actual - predicted_values)/actual)\nmape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# mean square error\nmse = np.mean((actual - predicted_values) ** 2)\nmse","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Forecast sales using the best fit ARIMA model\nThe next step is to foercast passengers for next 3 years i.e. for 1961, 1962, and 1963 through the above model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get forecast 36 steps (3 years) ahead in future\nn_steps = 36\npred_uc_99 = sarima_results.get_forecast(steps=36, alpha=0.01) # alpha=0.01 signifies 99% confidence interval\npred_uc_95 = sarima_results.get_forecast(steps=36, alpha=0.05) # alpha=0.05 95% CI\n\n# Get confidence intervals 95% & 99% of the forecasts\npred_ci_99 = pred_uc_99.conf_int()\npred_ci_95 = pred_uc_95.conf_int()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npred_ci_99.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_ci_95.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_steps = 36\nidx = pd.date_range(passengers_count.index[-1], periods=n_steps, freq='MS')\nfc_95 = pd.DataFrame(np.column_stack([np.power(10, pred_uc_95.predicted_mean), np.power(10, pred_ci_95)]), \n                     index=idx, columns=['forecast', 'lower_ci_95', 'upper_ci_95'])\nfc_99 = pd.DataFrame(np.column_stack([np.power(10, pred_ci_99)]), \n                     index=idx, columns=['lower_ci_99', 'upper_ci_99'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc_95.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfc_99.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fc_all = fc_95.combine_first(fc_99)\nfc_all = fc_all[['forecast', 'lower_ci_95', 'upper_ci_95', 'lower_ci_99', 'upper_ci_99']] # just reordering columns\nfc_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the forecast along with the confidence band\naxis = passengers_count.plot(label='Observed', figsize=(15, 6))\nfc_all['forecast'].plot(ax=axis, label='Forecast', alpha=0.7)\n#axis.fill_between(fc_all.index, fc_all['lower_ci_95'], fc_all['upper_ci_95'], color='k', alpha=.25)\naxis.fill_between(fc_all.index, fc_all['lower_ci_99'], fc_all['upper_ci_99'], color='k', alpha=.25)\naxis.set_xlabel('Years')\naxis.set_ylabel('Tractor Sales')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Diagnostics\n    1. Errors follows normality\n    2. Errors should not have auto correlation (ACF, no spikes beyond the limits)\n    3. Errors should not have any spikes (if the spikes are present, that particular time period, model didn't predict propoerly)"},{"metadata":{"trusted":true},"cell_type":"code","source":"sarima_results.plot_diagnostics(lags=30,figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The KDE plot of the residuals on the top right is almost similar with the normal distribution.\n- The qq-plot on the bottom left shows that the ordered distribution of residuals (blue dots) follows the linear trend of the samples taken from a standard normal distribution with N(0, 1). Again, this is a strong indication that the residuals are normally distributed.\n- The residuals over time (top left plot) don't display any obvious seasonality and appear to be white noise. This is confirmed by the autocorrelation (i.e. correlogram) plot on the bottom right, which shows that the time series residuals have low correlation with lagged versions of itself."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}